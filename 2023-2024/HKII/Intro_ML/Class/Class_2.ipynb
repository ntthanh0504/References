{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e910f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1865fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1., -1.],\n",
      "        [ 1., -1.,  1.]], grad_fn=<MmBackward0>)\n",
      "tensor([[-1.,  3., -3.]], grad_fn=<MmBackward0>)\n",
      "tensor([[ 2., -5.,  2.]], grad_fn=<SubBackward0>)\n",
      "tensor(33., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1, 1, -1], [0, -1, 1]], requires_grad=True, dtype=torch.float32)\n",
    "W1 = torch.tensor([[1, 0], [1, 2]], requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "A = torch.matmul(W1, X)\n",
    "A.retain_grad()\n",
    "W2 = torch.tensor([[1, -2]], requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "print(A)\n",
    "\n",
    "B = torch.matmul(W2, A)\n",
    "B.retain_grad()\n",
    "Y = torch.tensor([[1, -2 , -1]], requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "print(B)\n",
    "\n",
    "E = torch.subtract(Y, B)\n",
    "print(E)\n",
    "\n",
    "# Calculate the L2 regularization term\n",
    "C = torch.sum(torch.square(E))\n",
    "print(C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4403551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10., -14.],\n",
      "        [-20.,  28.]])\n",
      "tensor([[ 10., -18.]])\n",
      "tensor([[  4., -10.,   4.],\n",
      "        [ 16., -40.,  16.]])\n",
      "tensor([[  4., -10.,   4.]])\n",
      "tensor([[-4., 10., -4.]])\n",
      "tensor([[ -4.,  10.,  -4.],\n",
      "        [  8., -20.,   8.]])\n"
     ]
    }
   ],
   "source": [
    "C.backward()\n",
    "\n",
    "print(W1.grad)\n",
    "print(W2.grad)\n",
    "print(X.grad)\n",
    "print(Y.grad)\n",
    "print(B.grad)\n",
    "print(A.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "362dc3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 2.],\n",
      "        [1., 3.],\n",
      "        [1., 4.]], grad_fn=<StackBackward0>)\n",
      "tensor([[2., 3., 3., 5.]], requires_grad=True)\n",
      "tensor([[1.0000],\n",
      "        [0.9000]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.stack([torch.ones(4, requires_grad=True, dtype=torch.float32),\n",
    "                 torch.tensor([1, 2, 3, 4], requires_grad=True, dtype=torch.float32)], 1)\n",
    "Y = torch.tensor([[2, 3, 3, 5]], requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "# W = torch.matmul(torch.matmul(torch.inverse(torch.matmul(X, X.t())), X.t), Y)\n",
    "W = (X.T @ X).inverse() @ X.T @ Y.T\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87cd6bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 2., 3.],\n",
      "        [1., 3., 4.],\n",
      "        [1., 4., 3.]], grad_fn=<StackBackward0>)\n",
      "tensor([[1.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.]], grad_fn=<ViewBackward0>)\n",
      "tensor([[-0.3043],\n",
      "        [ 1.0870],\n",
      "        [ 0.3043]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X1 = torch.tensor([1, 2, 3, 4], requires_grad=True, dtype=torch.float32)\n",
    "X2 = torch.tensor([1, 3, 4, 3], requires_grad=True, dtype=torch.float32)\n",
    "X = torch.stack([torch.ones(4, requires_grad=True, dtype=torch.float32),\n",
    "                 X1, X2], 1)\n",
    "Y = torch.tensor([[1, 3, 4, 5]], requires_grad=True, dtype=torch.float32).reshape(4,1)\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "# W = torch.matmul(torch.matmul(torch.inverse(torch.matmul(X, X.t())), X.t), Y)\n",
    "W = (X.T @ X).inverse() @ X.T @ Y\n",
    "print(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785d035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
